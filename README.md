## TOPSIS Implementation for Sentence Similarity Models
This project demonstrates the application of the TOPSIS (Technique for Order of Preference by Similarity to Ideal Solution) method to evaluate and rank pre-trained sentence similarity models based on their performance metrics

## Description
TOPSIS is a multi-criteria decision-making method that ranks alternatives by comparing their distance to an ideal solution and an anti-ideal solution. This project evaluates sentence similarity models (e.g., BERT, SBERT, USE) using their similarity scores for various sentence pairs. The objective is to determine the best model based on weighted performance metrics.

## Dataset
The dataset consists of sentence pairs and their similarity scores generated by three models:
BERT
SBERT
USE (Universal Sentence Encoder)

![image](https://github.com/user-attachments/assets/1d414e6d-29f5-4fe0-87da-4ac23898deca)

## TOPSIS Algorithm
Steps:
Normalize the Decision Matrix:

Each element of the decision matrix is divided by the square root of the sum of squares of the corresponding column.

Weight the Normalized Matrix:

Multiply each column of the normalized matrix by its corresponding weight.
Determine Ideal and Anti-Ideal Solutions:

Ideal solution: Maximum value for benefit criteria.

Anti-Ideal solution: Minimum value for benefit criteria.

Calculate Distances:

Distance to Ideal Solution (D+)

Distance to Anti-Ideal Solution (D-)

Calculate the TOPSIS Score:
Relative closeness to the ideal solution:

Rank Alternatives:
Alternatives are ranked based on their TOPSIS scores in descending order.

## Results
The final DataFrame will display the TOPSIS scores and ranks for each model:

![image](https://github.com/user-attachments/assets/e7d6250a-2654-4fb9-9894-d5106c546381)

